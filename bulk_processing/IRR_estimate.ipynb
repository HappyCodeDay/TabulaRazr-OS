{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Applies a table filter across all extracted tables from a project and calculates \n",
    "# the net underwriter discount, and\n",
    "# the face value\n",
    "# for a specific type of table (standard case: two column with $ denominated key-value pairs)\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "import string\n",
    "\n",
    "sys.path.insert(0, os.path.pardir)\n",
    "\n",
    "from backend import *\n",
    "from data_query import *\n",
    "\n",
    "UPLOAD_FOLDER = os.path.join('..', 'static', 'ug')\n",
    "FILTER_FOLDER = os.path.join('..', 'static', 'filters')\n",
    "PROJECT = 'muni_bonds_bulk_2'\n",
    "FILTER = 'funds'\n",
    "\n",
    "path = os.path.join(UPLOAD_FOLDER, PROJECT, '*.tables.json')\n",
    "table_files = glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_string(s):\n",
    "    lc = s.encode('ascii', errors='ignore').lower()#.translate(remove_punctuation_map)\n",
    "    return lc.translate(None, string.punctuation + '0123456789').strip()\n",
    "    \n",
    "from collections import Counter\n",
    "\n",
    "table_counter = Counter()\n",
    "terms_stripped = Counter()\n",
    "terms_lc_cleaned = Counter()\n",
    "\n",
    "tables_looked_at = 0\n",
    "confidences = []\n",
    "no_result_files = []\n",
    "funny_tables = {}\n",
    "funny_rows = {}\n",
    "funny_values = ['NaN', 'Introduction', '']\n",
    "\n",
    "# Get those line items sufficient for IRR estimation\n",
    "# remark: improved query terms from TF analysis and annotation\n",
    "irr_estimate_dict = {'face_value' : ['Principal Amount', 'Par Amount', 'Face Amount'], \n",
    "                     'premium' : 'Issue Premium',\n",
    "                     'discount': 'Issue Discount',\n",
    "                     'underwriter_discount' : 'Underwriter Discount', \n",
    "                     'cost_of_issuance' : 'Costs of Issuance'}\n",
    "\n",
    "\n",
    "filter_file = os.path.join(FILTER_FOLDER, FILTER+'.json')\n",
    "with codecs.open(filter_file, \"r\", \"utf-8\", errors=\"replace\") as file:\n",
    "    _filter = json.load(file) \n",
    "\n",
    "print (\"Processing with filter %s\" % str(_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get all tables\n",
    "for i,f in enumerate(table_files):\n",
    "\n",
    "    with codecs.open(f, 'r', 'utf-8') as file:\n",
    "        tables = json.load(file)\n",
    "        tables_looked_at += len(tables)\n",
    "        \n",
    "        filename = f.split(r'/')[-1].replace('.tables.json', '')\n",
    "        \n",
    "        filter_results = []\n",
    "        for t in filter_tables(tables.values(), _filter):\n",
    "            if len(filter_results) == 0 or t[0] >= max(r[0] for r in filter_results):\n",
    "                filter_results.append(t)\n",
    "        \n",
    "        table_counter[len(filter_results)] += 1        \n",
    "        if len(filter_results):\n",
    "\n",
    "            #Only keep first one\n",
    "            confidence, table, _, _ = max( sorted( filter_results, key = lambda t: t[1]['begin_line'] ), \n",
    "                                          key = lambda t: t[0])\n",
    "            confidences.append(confidence)\n",
    "            if len(table['captions']) != 2 or table['subtypes'][1] != 'dollar':\n",
    "                funny_tables[filename] = table['begin_line']\n",
    "            for row in table['data']:\n",
    "                #Prune for rows that don't have (the right) data\n",
    "                #if True:\n",
    "                if len(row) > 1 and 'subtype' in row[1] and row[1]['subtype'] == 'dollar':\n",
    "                    first_term = row[0]['value'].strip()\n",
    "                    if first_term in funny_values:\n",
    "                        if filename in funny_rows: funny_rows[filename].append(row)\n",
    "                        else: funny_rows[filename] = [row]\n",
    "                        \n",
    "                    terms_stripped[first_term] += 1\n",
    "                    terms_lc_cleaned[clean_string(first_term)] += 1\n",
    "\n",
    "                #It's probably an interims caption (or from the TOC!)   \n",
    "                else:\n",
    "                    if filename in funny_rows: funny_rows[filename].append(row)\n",
    "                    else: funny_rows[filename] = [row]\n",
    "        else:\n",
    "            no_result_files.append(filename)\n",
    "        \n",
    "    if ( (i+1) % 100 ) == 0:\n",
    "        print (\"%i files and %i tables processed... with %i best matches and so far %i/%i unique terms\" % \\\n",
    "               (i+1, tables_looked_at, len(confidences), len(terms_stripped), len(terms_lc_cleaned)))\n",
    "\n",
    "print(table_counter.most_common())\n",
    "print(terms_lc_cleaned.most_common())\n",
    "#print(no_result_files)\n",
    "#print(funny_tables)\n",
    "#print(funny_rows)\n",
    "\n",
    "results = {'high_confidence_candidates' : table_counter.most_common(),\n",
    "           'tables_looked_at' : tables_looked_at,\n",
    "           'tables_canonical' : len(confidences),\n",
    "           'confidence_mean' : sum(confidences) / len(confidences),\n",
    "           'confidences' : confidences, \n",
    "           'unique_raw_terms' : len(terms_stripped),\n",
    "           'unique_cleaned_terms' : len(terms_lc_cleaned),\n",
    "           'raw_term_freq' : terms_stripped,\n",
    "           'clean_term_freq' : terms_lc_cleaned,\n",
    "           'no_table_files' : no_result_files,\n",
    "           'funny_tables' : funny_tables,\n",
    "           'funny_rows' : funny_rows\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save intermediate results\n",
    "with codecs.open(\"IRR_estimate.results.json\", \"w\", \"utf-8\") as file:\n",
    "    json.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Work from intermediate results\n",
    "with codecs.open(\"IRR_estimate.results.json\", \"r\", \"utf-8\") as file:\n",
    "    results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(results[\"no_table_files\"]) + len(results[\"confidences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "\n",
    "bold = xlwt.Style.easyxf(\"font: bold on\")\n",
    "\n",
    "def write_table(sheet, keys, values, row, c_offset = 0, column_style = bold):\n",
    "    for j, k in enumerate(keys):\n",
    "        sheet.write(row, c_offset+j, k, column_style)\n",
    "    row += 1\n",
    "    for v in values:\n",
    "        for j, vv in enumerate(v):\n",
    "            sheet.write(row, c_offset+j, vv)\n",
    "        row +=1\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_prefix = \"http://tabularazr.eastus.cloudapp.azure.com:7081/show/\"+PROJECT+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wkb = xlwt.Workbook(encoding='utf-8')\n",
    "s_summary, s_raw_tf, s_clean_tf, s_confidence, s_no_table, s_funny_tables, s_funny_rows = \\\n",
    "    (wkb.add_sheet(s) for s in ['summary', 'raw_TF', 'clean_TF', 'confidence', 'no_table', 'funny_tables', 'funny_rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "s_summary.write(i,0, 'Filter used', bold)\n",
    "s_summary.write(i,1, str(_filter))\n",
    "i+=2\n",
    "s_summary.write(i,0, 'Distribution of good table matches per document', bold)\n",
    "i+=1\n",
    "i = write_table(s_summary, ['Nr. of Table Candidates', 'Nr. of Documents'], \n",
    "                results[\"high_confidence_candidates\"], i)\n",
    "\n",
    "i+=1\n",
    "s_summary.write(i, 2, 'Total nr. of Table Candidates')\n",
    "s_summary.write(i, 3, 'out of..')\n",
    "i+=1\n",
    "s_summary.write(i, 2, results['tables_canonical'])\n",
    "s_summary.write(i, 3, results['tables_looked_at'])\n",
    "\n",
    "i = write_table(s_confidence, ['Confidence in best Table found'], ([c] for c in results['confidences']), 0)\n",
    "i = write_table(s_no_table, ['Files with no suitable table found', 'URL'], \n",
    "                ( ([c], url_prefix+c) for c in results['no_table_files'] ), 0)\n",
    "\n",
    "i = write_table(s_raw_tf, ['Term (raw)', 'Frequency'], \n",
    "                (tf for tf in Counter(results['raw_term_freq']).most_common() ), 0)\n",
    "i = write_table(s_clean_tf, ['Term (cleaned)', 'Frequency'], \n",
    "                (tf for tf in Counter(results['clean_term_freq']).most_common() ), 0)\n",
    "\n",
    "s_funny_tables.write(0,4, \"[as returned by filter but with <> 2 rows, and/or no $ value in the 2nd column]\")\n",
    "i = write_table(s_funny_tables, ['Funny Tables in File', 'Table ID',  'URL'], \n",
    "                ( (f, t, url_prefix+f+'#'+str(t)) for f, t in results['funny_tables'].iteritems() ), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wkb.save('fund_filter_results.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f, t in results['funny_tables'].iteritems():\n",
    "    print (f, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results['funny_tables']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
