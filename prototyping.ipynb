{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TabulaRazr - specific to calculate  - TABLE Parser\n",
    "#Infers a table with arbitrary number of columns from reoccuring patterns in text lines\n",
    "#(c) Alexander Hirner 2016, no redistribution without permission\n",
    "#Contributions: ____ (refactoring), UI styling (), ....\n",
    "\n",
    "\n",
    "#Main assumptions Table identificatin:\n",
    "#1) each row is either in one line or not a row at all\n",
    "#2) each column features at least one number (=dollar amount)\n",
    "#2a) each column features at least one date-like string [for time-series only]\n",
    "#3) a table exists if rows are in narrow consecutive order and share similarities --> scoring algo [DONE] \n",
    "#4) each column is separated by more than x consecutive whitespace indicators (e.g. '  ' or '..')\n",
    "\n",
    "#Feature List Todo:\n",
    "#1) Acknowledge footnotes / make lower meta-data available\n",
    "#2) make delimiter length smartly dependent on number of columns (possible iterative approach)\n",
    "#3) improve captioning: expand non canonical values in tables [DONE] .. but not to the extent how types match up  --> use this to further\n",
    "## delineate between caption and headers\n",
    "#4) UI: parameterize extraction on the show page on the fly\n",
    "#5) deeper type inference on token level: type complex [DONE], subtype header (centered, capitalized), \n",
    "## subtype page nr., type free flow [DONE, need paragraph]\n",
    "#5a) re\n",
    "#6) Respect negative values with potential '-' for numerical values\n",
    "#7)\n",
    "#8) classify tables with keywords (Muni Bonds) and unsupervised clustering (Hackathon)\n",
    "#9) Restructure folder and URI around MD5 hash (http://stackoverflow.com/questions/24570066/calculate-md5-from-werkzeug-datastructures-filestorage-without-saving-the-object)\n",
    "#10) proper logging\n",
    "#11) include tesseract for OCR capabilities (quickstart guide: http://pythontips.com/2016/02/25/ocr-on-pdf-files-using-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "import string\n",
    "\n",
    "from backend import *\n",
    "from data_query import *\n",
    "\n",
    "UPLOAD_FOLDER = './static/ug'\n",
    "PROJECT = 'muni_bonds_bulk'\n",
    "\n",
    "path = os.path.join(UPLOAD_FOLDER, PROJECT, '*.tables.json')\n",
    "table_files = glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with filter {u'headers': {u'threshold': 0.35, u'terms': [u'USES OF FUNDS']}, u'name': u'Estimated use and sources of funds'}\n"
     ]
    }
   ],
   "source": [
    "def clean_string(s):\n",
    "    lc = s.encode('ascii', errors='ignore').lower()#.translate(remove_punctuation_map)\n",
    "    return lc.translate(None, string.punctuation + '0123456789').strip()\n",
    "    \n",
    "from collections import Counter\n",
    "\n",
    "table_counter = Counter()\n",
    "terms_stripped = Counter()\n",
    "terms_lc_cleaned = Counter()\n",
    "\n",
    "tables_looked_at = 0\n",
    "confidences = []\n",
    "no_result_files = []\n",
    "funny_tables = {}\n",
    "funny_rows = {}\n",
    "funny_values = ['NaN', 'Introduction', '']\n",
    "\n",
    "filter_file = os.path.join('static', 'filters', 'funds.json')\n",
    "with codecs.open(filter_file, \"r\", \"utf-8\", errors=\"replace\") as file:\n",
    "    _filter = json.load(file) \n",
    "\n",
    "print (\"Processing with filter %s\" % str(_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with filter {u'headers': {u'threshold': 0.35, u'terms': [u'USES OF FUNDS']}, u'name': u'Estimated use and sources of funds'}\n",
      "100 files and 5689 tables processed... with 74 best matches and so far 84/69 unique terms\n",
      "200 files and 11545 tables processed... with 147 best matches and so far 131/105 unique terms\n",
      "[(1, 119), (0, 53), (2, 18), (3, 7), (5, 3), (4, 2)]\n",
      "[('total sources', 65), ('total uses', 62), ('total sources of funds', 56), ('total uses of funds', 55), ('deposit to escrow fund', 29), ('principal amount of bonds', 27), ('total', 23), ('par amount of the bonds', 16), ('par amount of bonds', 14), ('par amount', 11), ('deposit to construction fund', 11), ('principal amount of the bonds', 9), ('deposit to project fund', 9), ('costs of issuance', 8), ('', 7), ('escrow fund', 7), ('principal amount of refunding bonds', 7), ('principal amount', 7), ('deposit to building fund', 6), ('building fund', 6), ('principal amount of certificates', 6), ('principal amount of series  bonds', 5), ('deposit into the building fund', 3), ('underwriters discount', 3), ('deposit to fund ii to make home loans', 2), ('principal amount of the cibs', 2), ('debt service fund', 2), ('deposit into escrow fund', 2), ('total applications of funds', 2), ('par amount of series a bonds', 2), ('project fund', 2), ('deposit to project construction fund', 2), ('deposit to district proceeds fund', 2), ('par amount of certificates', 2), ('principal amount of notes', 2), ('principal amount of series d bonds', 2), ('par amount of notes', 2), ('deposit to escrow account', 2), ('principal amount of  bonds', 1), ('obligations', 1), ('deposit into the reserve fund', 1), ('principal amount of the notes', 1), ('par amount of refunding bonds', 1), ('escrow deposit', 1), ('total fund balances', 1), ('principal', 1), ('deposit to the building fund', 1), ('deposit to the construction fund', 1), ('prior bonds redemption', 1), ('refunding of series  bonds', 1), ('balance december', 1), ('par amount of the cibs', 1), ('deposit to project account', 1), ('general fund', 1), ('series d building fund', 1), ('accrued interest', 1), ('cash deposit to the escrow fund', 1), ('refunded notes escrow deposit', 1), ('deposit to project fund construction and costs of issuance', 1), ('initial principal amount', 1), ('deposit with refunded obligations paying agent', 1), ('special emergency authorizations', 1), ('construction fund deposit', 1), ('inventories', 1), ('initial principal amount of series  bonds', 1), ('cash deposit', 1), ('project fund deposit', 1), ('original principal amount of series  bonds', 1), ('par amount of series  bonds', 1), ('aggregate principal amount of current interest bonds', 1), ('deposit to the escrow fund', 1), ('net original issue premium', 1), ('deposit to redemption fund', 1), ('funds to defease  notes', 1), ('principal amount of revenue and refunding bonds', 1), ('cash deposit to escrow fund', 1), ('deposit with paying agent for refunded bonds', 1), ('deposit into school facilities account of construction fund', 1), ('prepayment fund', 1), ('bonds payable october', 1), ('for payment of the refunded notes', 1), ('refunded bonds escrow deposit', 1), ('balance january', 1), ('deposit to project construction fundrounding amount', 1), ('proceeds of series a bonds', 1), ('plus accrued interest', 1), ('agent', 1), ('project costs', 1), ('bonds payable sept', 1), ('principal amount of cabs', 1), ('refunding of  certificates', 1), ('nan', 1), ('bonds escrow fund', 1), ('principal amount of the certificates', 1), ('deposits to escrow funds', 1), ('district cash', 1), ('deposit into capitalized interest subaccount of bond fund', 1), ('the construction fund', 1), ('bond insurance', 1), ('principal amount of series b bonds', 1), ('utility improvement fund', 1), ('deposit to escrow for prior bonds', 1), ('issuance expenses', 1), ('principal amount of series a notes', 1), ('face amount of bonds', 1), ('deposit for redemption of refunded bonds', 1), ('principal amount of series c bonds', 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Get all tables\n",
    "for i,f in enumerate(table_files):\n",
    "\n",
    "    with codecs.open(f, 'r', 'utf-8') as file:\n",
    "        tables = json.load(file)\n",
    "        tables_looked_at += len(tables)\n",
    "        \n",
    "        filename = f.split(r'/')[-1].replace('.tables.json', '')\n",
    "        \n",
    "        filter_results = []\n",
    "        for t in filter_tables(tables.values(), _filter):\n",
    "            if len(filter_results) == 0 or t[0] >= max(r[0] for r in filter_results):\n",
    "                filter_results.append(t)\n",
    "        \n",
    "        table_counter[len(filter_results)] += 1        \n",
    "        if len(filter_results):\n",
    "\n",
    "            #Only keep first one\n",
    "            confidence, table, _, _ = max( sorted( filter_results, key = lambda t: t[1]['begin_line'] ), \n",
    "                                          key = lambda t: t[0])\n",
    "            confidences.append(confidence)\n",
    "            if len(table['captions']) != 2 or table['subtypes'][1] != 'dollar':\n",
    "                funny_tables[filename] = table['begin_line']\n",
    "            for row in table['data']:\n",
    "                #Prune for rows that don't have (the right) data\n",
    "                #if True:\n",
    "                if len(row) > 1 and 'subtype' in row[1] and row[1]['subtype'] == 'dollar':\n",
    "                    first_term = row[0]['value'].strip()\n",
    "                    if first_term in funny_values:\n",
    "                        if filename in funny_rows: funny_rows[filename].append(row)\n",
    "                        else: funny_rows[filename] = [row]\n",
    "                        \n",
    "                    terms_stripped[first_term] += 1\n",
    "                    terms_lc_cleaned[clean_string(first_term)] += 1\n",
    "\n",
    "                #It's probably an interims caption (or from the TOC!)   \n",
    "                else:\n",
    "                    if filename in funny_rows: funny_rows[filename].append(row)\n",
    "                    else: funny_rows[filename] = [row]\n",
    "        else:\n",
    "            no_result_files.append(filename)\n",
    "        \n",
    "    if ( (i+1) % 100 ) == 0:\n",
    "        print (\"%i files and %i tables processed... with %i best matches and so far %i/%i unique terms\" % \\\n",
    "               (i+1, tables_looked_at, len(confidences), len(terms_stripped), len(terms_lc_cleaned)))\n",
    "\n",
    "    if i > 200: break\n",
    "\n",
    "\n",
    "print(table_counter.most_common())\n",
    "print(terms_lc_cleaned.most_common())\n",
    "#print(no_result_files)\n",
    "#print(funny_tables)\n",
    "#print(funny_rows)\n",
    "\n",
    "results = {'high_confidence_candidates' : table_counter.most_common(),\n",
    "           'tables_looked_at' : tables_looked_at,\n",
    "           'tables_canonical' : len(confidences),\n",
    "           'confidence_mean' : sum(confidences) / len(confidences),\n",
    "           'confidences' : confidences, \n",
    "           'unique_raw_terms' : len(terms_stripped),\n",
    "           'unique_cleaned_terms' : len(terms_stripped),\n",
    "           'raw_term_freq' : terms_stripped,\n",
    "           'clean_term_freq' : terms_lc_cleaned,\n",
    "           'no_table_files' : no_result_files,\n",
    "           'funny_tables' : funny_tables,\n",
    "           'funny_rows' : funny_rows\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"funds_stats.results.json\", \"w\", \"utf-8\") as file:\n",
    "    json.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"funds_stats.results.json\", \"r\", \"utf-8\") as file:\n",
    "    results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6777"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results[\"no_table_files\"]) + len(results[\"confidences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "\n",
    "bold = xlwt.Style.easyxf(\"font: bold on\")\n",
    "\n",
    "def write_table(sheet, keys, values, row, c_offset = 0, column_style = bold):\n",
    "    for j, k in enumerate(keys):\n",
    "        sheet.write(row, c_offset+j, k, column_style)\n",
    "    row += 1\n",
    "    for v in values:\n",
    "        for j, vv in enumerate(v):\n",
    "            sheet.write(row, c_offset+j, vv)\n",
    "        row +=1\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wkb = xlwt.Workbook(encoding='utf-8')\n",
    "s_summary, s_raw_tf, s_clean_tf, s_confidence, s_no_table, s_funny_tables, s_funny_rows = \\\n",
    "    (wkb.add_sheet(s) for s in ['summary', 'raw_TF', 'clean_TF', 'confidence', 'no_table', 'funny_tables', 'funny_rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "s_summary.write(i,0, 'Filter used', bold)\n",
    "s_summary.write(i,1, str(_filter))\n",
    "i+=2\n",
    "s_summary.write(i,0, 'Distribution of good table matches per document', bold)\n",
    "i+=1\n",
    "i = write_table(s_summary, ['Nr. of Table Candidates', 'Nr. of Documents'], \n",
    "                results[\"high_confidence_candidates\"], i)\n",
    "\n",
    "i+=1\n",
    "s_summary.write(i, 2, 'Total nr. of Table Candidates')\n",
    "s_summary.write(i, 3, 'out of..')\n",
    "i+=1\n",
    "s_summary.write(i, 2, results['tables_canonical'])\n",
    "s_summary.write(i, 3, results['tables_looked_at'])\n",
    "\n",
    "i = write_table(s_confidence, ['Confidence in best Table found'], ([c] for c in results['confidences']), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wkb.save('fund_filter_results.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "#print (fuzz.partial_ratio(\"this is a test!\", \"this text is\"))\n",
    "#print (fuzz.partial_ratio(\"USES OF FUNDS\", \"USES from FUNDS\"))\n",
    "#print (fuzzy_str_match(\"aaaaaaaaaa text this\", \"this test is\"))\n",
    "\n",
    "print (fuzzy_str_match(\"USES OF FUNDS\", \"USES OF FUNDS\"))\n",
    "print (fuzzy_str_match(\"USES OF FUNDS\", \"USES of FUNDS\"))\n",
    "print (fuzzy_str_match(\"USES OF FUNDS\", \"uses of funds\"))\n",
    "print (fuzzy_str_match(\"USES OF FUNDS\", \"USES which include other FUNDS\"))\n",
    "\n",
    "\n",
    "print (fuzzy_str_match(\"USES OF FUNDS\", \"Note 5 - Assets Limited as to Use\"))\n",
    "print (fuzzy_str_match(\"USES OF FUNDS\", \"FINANCIAL STATEMENT AMOUNTS - Continued\"))\n",
    "\n",
    "print (fuzzy_str_match(\"USES OF FUNDS\", \"FUNDS OF USES\"))\n",
    "\n",
    "\n",
    "print (fuzzy_str_match(\"USES OF FUNDS\", \"TABLE OF CONTENTS\"))\n",
    "\n",
    "print (fuzzy_str_match(\"Debt Service\", \"Total Periodic Debt Service\"))\n",
    "\n",
    "#print (fuzzy_str_match(\"USES OF FUNDS\", \"Note 5 - Assets Limited as to Use\"))\n",
    "#print (fuzzy_str_match(\"USES OF FUNDS\", \"FINANCIAL STATEMENT AMOUNTS - Continued\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (fuzzy_str_match(\"Maturity\", \"ii\"))\n",
    "#print (fuzz.partial_ratio(\"Maturity\", \"i\"))\n",
    "print (fuzzy_str_match(\"Maturity\", \"Matarit\"))\n",
    "print (fuzzy_str_match(\"Maturity\", \"i\"))\n",
    "print (fuzzy_str_match(\"Maturity\", \"     i   \"))\n",
    "\n",
    "\n",
    "print (\"Maturity\".lower() in \"i\".lower())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
